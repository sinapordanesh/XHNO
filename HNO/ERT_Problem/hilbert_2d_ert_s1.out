Starting run at: Thu 14 Nov 2024 01:11:31 PM EST
/home/sinpo/repos/XNO/HNO/ERT_Problem/./ERT_hilbert.py:567: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load('best_modelV1.pth'))
torch.Size([80000, 40, 100])
torch.Size([80000, 40, 100])
torch.Size([100, 40, 100])
torch.Size([100, 40, 100])
torch.Size([100, 40, 100])
torch.Size([100, 40, 100])
40
100
Devide is: cuda
999937
0 29.57521322928369 0.20687544951438905 0.1504734230041504
1 27.98446083208546 0.1119485267162323 0.14416227340698243
2 27.831099059898406 0.09692424626648426 0.10352238655090332
3 27.903980924282223 0.08435960935950279 0.11137364387512207
4 28.005539598874748 0.08212356124818325 0.11794122695922851
5 27.87345686228946 0.07710505382418632 0.07025533676147461
6 27.8773796511814 0.07441253074109554 0.09619955539703369
7 27.97194840107113 0.06927410231232643 0.07204301118850708
8 27.92910509184003 0.06888914041221142 0.06765654802322388
9 27.93759279185906 0.06640094102323055 0.12099714279174804
10 27.905564931686968 0.06662449332177639 0.07501763820648194
11 27.91634774999693 0.06546062532961369 0.08831211566925048
12 27.75829336605966 0.06162697547972202 0.07640597105026245
13 27.777936356142163 0.06488312782645225 0.07293962717056274
14 27.789092828985304 0.062075802147388455 0.05844334363937378
15 27.91453415900469 0.05887797512710095 0.10341060638427735
16 27.780408137012273 0.06070390174388886 0.06113407850265503
17 27.990011570975184 0.06098464847207069 0.07202855825424194
18 27.872535995207727 0.05729275129139423 0.056316235065460206
19 27.94897489901632 0.05429101620465517 0.06218452453613281
20 28.008520751725882 0.05444820585250854 0.062195460796356204
21 27.861075629014522 0.05545522913187742 0.04567368626594544
22 27.86991131398827 0.05412801768928766 0.06716571807861328
23 27.84495233837515 0.05402745101749897 0.05306644678115845
24 28.04542549001053 0.05357083292752504 0.04723834753036499
25 27.928027448710054 0.05416073232889176 0.05132703304290771
26 28.101412867195904 0.04995148019939661 0.04630431652069092
27 27.853778195101768 0.04811647607088089 0.04710149049758911
28 27.885844114702195 0.050511416171491144 0.043583117723464966
29 27.946647258941084 0.04889231558144093 0.05169111967086792
30 27.948890820145607 0.04919488101899624 0.04886576414108276
31 28.019942624028772 0.04707446896582842 0.04342250347137451
32 27.954716749023646 0.048788699889183045 0.04550813436508179
33 27.918421200010926 0.04559048835039139 0.062208893299102785
34 27.899275008123368 0.045590165668725965 0.042891931533813474
35 27.79411279782653 0.04547725279927254 0.04536049842834473
36 27.93649097159505 0.04372921895384788 0.04055842876434326
37 27.809618764091283 0.045446269731223586 0.038620076179504394
38 27.88140505179763 0.04611659903675318 0.04248282194137573
39 27.920843017753214 0.04148911509662866 0.04595350742340088
40 27.8368675080128 0.04257761265784502 0.047943027019500734
41 27.850293010938913 0.04143198865652084 0.05836387634277344
42 27.82916818698868 0.0411578349262476 0.04046167612075806
43 27.905324769206345 0.039539019632339474 0.04095286369323731
44 27.857504342217 0.04176114940196276 0.03842407464981079
45 27.83408263605088 0.03783440292030573 0.03975942969322205
46 28.09795577591285 0.04132633794695139 0.045147173404693604
47 27.973209880292416 0.038515746842324734 0.043217096328735355
48 27.70901941973716 0.03680044934302568 0.03797332763671875
49 27.767932878341526 0.039422607378661635 0.03733792304992676
50 27.79590889485553 0.03725461218804121 0.03581609964370727
51 27.853089896962047 0.03526383703351021 0.03695341944694519
52 27.95484527107328 0.03638973477333784 0.04016246914863587
53 27.988651474006474 0.03601378431767225 0.036059439182281494
54 27.915528484154493 0.03369243120849132 0.03421602606773377
55 28.034023962914944 0.03476593128442764 0.038368185758590696
56 27.869960898067802 0.03460882048904896 0.0378782057762146
57 27.792425925843418 0.032220077557861805 0.03669819235801697
58 27.809773535002023 0.033929919770359994 0.032254843711853026
59 27.800994116812944 0.031286734671890734 0.035334361791610716
60 27.934878220316023 0.031292785024642944 0.035500078201293944
61 28.04522525984794 0.03238575712442398 0.03537312984466553
62 27.82501440308988 0.030190781559050084 0.030170366764068604
63 27.90842232014984 0.03020706164985895 0.03299959659576416
64 27.926640714053065 0.029946684254705907 0.033583364486694335
65 27.862595412880182 0.029545838218927385 0.03447325348854065
66 27.79446763219312 0.028839323358237745 0.03177253007888794
67 27.772062472999096 0.02874681398421526 0.031039135456085207
68 27.965118810068816 0.028390105538070202 0.031385382413864134
69 27.84404234867543 0.028003299506008626 0.03016021251678467
70 27.840716135222465 0.027556794109940528 0.028704600334167482
71 27.85074097290635 0.027011299996078014 0.02867512106895447
72 27.855594447813928 0.026845491705834865 0.03373520374298096
73 27.849273656029254 0.026369804634153844 0.02847214221954346
74 27.811888210009784 0.026002893839776515 0.027534890174865722
75 27.908516458701342 0.025653769353032114 0.02699461340904236
76 27.860618534032255 0.0252937025770545 0.02804832696914673
77 27.78960371762514 0.024937141056358813 0.027322031259536743
78 27.84111793199554 0.024651949508488178 0.02722271203994751
79 27.88295021560043 0.024241313645243644 0.02755290985107422
80 27.91205548401922 0.024040666899085045 0.02728301763534546
81 27.944696099031717 0.02369650893583894 0.02568564772605896
82 27.772882838733494 0.023318309704214335 0.02588828921318054
83 27.853761240839958 0.023139666952937843 0.02480518341064453
84 28.081491299904883 0.022786897410452367 0.024687914848327636
85 28.028237863909453 0.02255267011746764 0.024931076765060425
86 27.940247758757323 0.02229300461933017 0.024637402296066285
87 27.878141696099192 0.022020686262100936 0.02471156120300293
88 28.02819916093722 0.02181090773642063 0.024028713703155517
89 28.028884613886476 0.021540978037565946 0.024072149991989134
90 28.180613711941987 0.021365083081275226 0.023364071249961853
91 27.949385874904692 0.02119087217450142 0.023514946699142458
92 28.041716387029737 0.021015642209351062 0.023041359782218933
93 28.052417872007936 0.020866129229217767 0.023314279913902284
94 27.9106095158495 0.02073686223551631 0.02342272937297821
95 27.999110023956746 0.020613574362546204 0.02331510365009308
96 27.94121419126168 0.020505310817062854 0.02295290946960449
97 28.043517494108528 0.020429565676301716 0.02289946973323822
98 27.942648587282747 0.020378063485771418 0.02293647885322571
99 27.97556141624227 0.020353313686698675 0.022954490184783936
Time taken for predictions on new_test.mat: 0.02065562130883336 seconds
Job finished with exit code 0 at: Thu 14 Nov 2024 01:58:45 PM EST
