Starting run at: Sun 24 Nov 2024 07:23:51 PM EST
/home/sinpo/repos/XNO/HNO/ERT_Problem/ERT_hilbert.py:501: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"best_model_{pfn}.pth"))
torch.Size([80000, 40, 100])
torch.Size([80000, 40, 100])
torch.Size([100, 40, 100])
torch.Size([100, 40, 100])
torch.Size([100, 40, 100])
torch.Size([100, 40, 100])
40
100
Devide is: cuda
999937
0 33.65784560699831 0.2971304309785366 0.1890720272064209
1 32.24562319200777 0.17678936243653298 0.16630796909332277
2 32.12926400800643 0.15393661376833917 0.14731630325317382
3 32.544471215005615 0.13926312790513037 0.20605202674865722
4 32.413950689995545 0.13466985704600812 0.16048799514770506
5 32.42646737000905 0.12654550595879555 0.12855112552642822
6 32.467747523012804 0.12300827656388283 0.12952515602111817
7 32.530008652989636 0.115865524995327 0.0950007438659668
8 32.42340973899991 0.11735405969023704 0.08382304191589356
9 32.204696087996126 0.1134909383147955 0.11071163654327393
10 32.19688832599786 0.11206770496666431 0.08789766788482666
11 32.20449153300433 0.10663712750077248 0.07266855955123902
12 31.99653654899157 0.10725161780714988 0.09395846843719483
13 32.33936722500948 0.10574281117022037 0.10723780632019043
14 32.362815902990405 0.1037333003371954 0.0761348557472229
15 32.30643554100243 0.09903179988563061 0.16843093395233155
16 32.2903878549987 0.10312399274408818 0.08855385303497315
17 32.00785456900485 0.09780460850000382 0.08614798545837403
18 32.200603179997415 0.09439742811322212 0.06052564859390259
19 32.10805536499538 0.09743100615143777 0.10232103347778321
20 32.10273963699001 0.09324331796467304 0.06275817632675171
21 32.08368877900648 0.08889144695997238 0.057103793621063235
22 32.1174240130058 0.09495317728221417 0.061104094982147215
23 32.1750709629996 0.08636565904021264 0.07271430015563965
24 32.000728968996555 0.09225465371012688 0.1078418254852295
25 32.415748170009465 0.0860988643616438 0.06013181447982788
26 32.056087703997036 0.08910879757404327 0.10459601879119873
27 32.249900398994214 0.08578855985701084 0.056281898021698
28 32.35305023200635 0.08472101246416569 0.05822938203811646
29 32.37557688799279 0.08244048917293549 0.07707817792892456
30 32.22815354600607 0.08376447825133801 0.06255185604095459
31 32.12323094399471 0.08108307584822178 0.05187666416168213
32 31.947042783998768 0.08067931593358517 0.08313358306884766
33 32.33612458099378 0.083004641315341 0.05916930198669434
34 32.03783029099577 0.08137901502847672 0.06006361961364746
35 32.23308814999473 0.07723356058001518 0.06404772520065308
36 31.893868732993724 0.0774630302131176 0.07034820795059205
37 32.32512327999575 0.07904086537063122 0.06465389728546142
38 32.49334648800141 0.0746722601890564 0.054531941413879396
39 32.19611556798918 0.07147349491119384 0.05240572690963745
40 31.805470947001595 0.07372649648189544 0.07600091218948364
41 31.916735509003047 0.0735078149408102 0.06418481826782227
42 32.39576041699911 0.06827770348787308 0.05539361238479614
43 32.67831208999269 0.07321255869865417 0.055186688899993896
44 32.180368610992446 0.06774555804431438 0.0588377594947815
45 32.28718945699802 0.0706699778020382 0.04698869228363037
46 32.26107834800496 0.06781347766220569 0.06193233251571655
47 32.349642393004615 0.06660045237243176 0.051579601764678955
48 32.02753570499772 0.06359811094403267 0.056537051200866696
49 32.0251579110045 0.06383284825980663 0.048337855339050294
50 32.39514685800532 0.06526792279779911 0.05264995813369751
51 32.24836775899166 0.06121627513170242 0.05193697452545166
52 32.34329499899468 0.0621068252235651 0.05399371147155762
53 31.949263579997933 0.05967736632525921 0.06021514654159546
54 32.182167231992935 0.057595496755838395 0.06061548948287964
55 32.26045713100757 0.05982915561497212 0.05428655862808227
56 31.955784768011654 0.05532047085613012 0.04481128692626953
57 32.38402128400048 0.055668959072232245 0.04410017490386963
58 32.26942882400181 0.05472702660858631 0.05457181453704834
59 31.998849969997536 0.05423365682661534 0.04980698823928833
60 32.195031367009506 0.053082020923495295 0.043886426687240604
61 32.2064983429882 0.05541034358888865 0.05117985725402832
62 32.51594459199987 0.05082617760300636 0.042269935607910154
63 32.22810020399629 0.05152860530167818 0.039627881050109864
64 32.24747105401184 0.04908392711132765 0.04322896599769592
65 32.2790042800043 0.04849665732383728 0.04257004261016846
66 32.08911356599128 0.048228049251437186 0.042862279415130614
67 32.237451870998484 0.04608834089785814 0.03937484264373779
68 32.50398860900896 0.04592695008218289 0.039598690271377565
69 32.036567354007275 0.045470453901588916 0.044094929695129396
70 32.06347914399521 0.04415616461187601 0.03703644394874573
71 31.723020210993127 0.043746793214976785 0.03611058235168457
72 32.42677438400278 0.04260057823807001 0.037646048069000244
73 32.290315512989764 0.04206273198127747 0.03602524638175964
74 32.39437015200383 0.04114775942116976 0.037786072492599486
75 32.27614901099878 0.040534198029339316 0.03596746802330017
76 32.36632481199922 0.03952556496411562 0.03439832091331482
77 32.15648593599326 0.039267434106767175 0.03387732982635498
78 32.131188496990944 0.03825189572870731 0.033449835777282715
79 31.901367755010142 0.03761130012720823 0.03087921142578125
80 31.828118972000084 0.03686034631431103 0.03369945764541626
81 32.12270900700241 0.036305650739371774 0.032480131387710574
82 31.81517702199926 0.03561225858032704 0.03082994818687439
83 32.06624405400362 0.034945071306824685 0.029805831909179688
84 32.05345969799964 0.034354034762084484 0.029502246379852295
85 32.2699549520039 0.033820713007450105 0.030469368696212768
86 32.22246238999651 0.03329656457901001 0.03012960195541382
87 32.18696641801216 0.03274135919511318 0.028757307529449463
88 32.04763481799455 0.032263384805619716 0.030891112089157104
89 31.995575113003724 0.03180756336599588 0.027592009305953978
90 31.933443087007618 0.031372380369901656 0.028320560455322264
91 32.265361871002824 0.031006030432879923 0.028133084774017336
92 31.91947075499047 0.03068707923293114 0.027282609939575195
93 32.23991356800252 0.030352118620276453 0.02728665828704834
94 32.02592221500527 0.030098194752633572 0.02726493239402771
95 31.941779265995137 0.0298619486913085 0.02725975513458252
96 32.457705810986226 0.029690853135287763 0.027319358587265016
97 32.21483918299782 0.02957091772556305 0.026894323825836182
98 32.05419924399757 0.029503729620575906 0.02695145010948181
99 31.813874290004605 0.029453152188658713 0.02688347578048706
Time taken for predictions on new_test.mat: 0.03115905399317853 seconds
Job finished with exit code 0 at: Sun 24 Nov 2024 08:18:11 PM EST
