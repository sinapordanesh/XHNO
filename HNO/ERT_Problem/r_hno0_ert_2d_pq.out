Starting run at: Sun 24 Nov 2024 06:26:19 PM EST
/home/sinpo/repos/XNO/HNO/ERT_Problem/ERT_hilbert.py:501: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"best_model_{pfn}.pth"))
torch.Size([66000, 40, 100])
torch.Size([66000, 40, 100])
torch.Size([100, 40, 100])
torch.Size([100, 40, 100])
torch.Size([100, 40, 100])
torch.Size([100, 40, 100])
40
100
Devide is: cuda
999937
0 26.60504758299794 0.24836303787520436 0.1948760414123535
1 24.844615691021318 0.12072886207609465 0.09966708421707153
2 25.076851869001985 0.10834636372508424 0.054100368022918705
3 24.714073133975035 0.09541579788381403 0.1624574565887451
4 24.755069397971965 0.08838353229110892 0.04806753635406494
5 24.758359889005078 0.07772018591201667 0.06820082902908325
6 24.732662444002926 0.07478547817829884 0.04427905797958374
7 24.725216904014815 0.07675368892243414 0.033544232845306395
8 24.747087375988485 0.07408102563475118 0.04527003288269043
9 24.780726026016055 0.06976939973686681 0.12891160011291503
10 24.881089272006648 0.06390598187843959 0.0758167839050293
11 24.82037084401236 0.06141578277132728 0.05157270431518555
12 24.826307570998324 0.05655219794764663 0.13201570987701416
13 24.856504043011228 0.0587351552175753 0.13065722942352295
14 24.726406927016797 0.06418199300224131 0.05841633558273315
15 24.831432037986815 0.05817360584663622 0.10284067153930664
16 24.85722536299727 0.06041929817831877 0.0974091911315918
17 24.804204078012845 0.05910079770196568 0.022445194721221924
18 24.744324250001227 0.04877822232607639 0.030261447429656984
19 24.819241755991243 0.047865256768284424 0.06461448669433593
20 24.838248573010787 0.05792043241045692 0.02486886262893677
21 24.80590078700334 0.048911489183252506 0.036977596282958984
22 24.890187101991614 0.04619130357106527 0.029948151111602782
23 24.856449144979706 0.0469987615870707 0.02066297173500061
24 24.848223755980143 0.04103965319738244 0.029657996892929077
25 24.83576836399152 0.046171319887493595 0.02974963665008545
26 24.922405431978405 0.0475980767779278 0.024390016794204713
27 24.912159715982853 0.048550469563765956 0.0317468786239624
28 24.873309135989984 0.03767938278028459 0.021639084815979003
29 24.862777830974665 0.036259989214665965 0.023141443729400635
30 24.840988612006186 0.04118779469439478 0.08158001899719239
31 24.83179825299885 0.038447301590984514 0.029348366260528565
32 24.803664719016524 0.040778995964563254 0.024204355478286744
33 24.80395076799323 0.03337574456406362 0.06322084903717042
34 24.85878320300253 0.03358493014989477 0.12299638748168945
35 24.848244413995417 0.02707384284698602 0.017340006828308104
36 24.868701232015155 0.034748913936542745 0.017456926107406616
37 24.855803418002324 0.032364123929630624 0.020623097419738768
38 24.869793610996567 0.03911963127959858 0.01685863196849823
39 24.797168406978017 0.029500911564537973 0.01786612868309021
40 24.899944397009676 0.021643581700144392 0.014879063367843628
41 24.83420229400508 0.030229383431600802 0.019136627316474916
42 24.74370020200149 0.029912335878971852 0.018581026792526247
43 24.94318555400241 0.030431469331185023 0.034510189294815065
44 24.88163676302065 0.020687374116796435 0.017835441827774048
45 24.944017492001876 0.030407442929166736 0.017548890709877016
46 24.87582335699699 0.027341876524867432 0.023870713710784912
47 24.85713130401564 0.019497752824516008 0.012694804668426514
48 24.841364602994872 0.028735321430545864 0.014455875158309936
49 24.96029227101826 0.024690018298951063 0.015887050628662108
50 24.952241569990292 0.018227564372799612 0.015204972624778747
51 24.887875509011792 0.024248285002780683 0.013196221590042113
52 24.98597083898494 0.017644366888385832 0.017571079730987548
53 24.739180277014384 0.021198939033529974 0.01568678915500641
54 24.856508591008605 0.021446411076820257 0.03260049819946289
55 24.899033013993176 0.01821645880287344 0.012580969333648682
56 24.596527713001706 0.016303696730823228 0.015207196474075318
57 24.90610024202033 0.020361410841797337 0.013663105964660645
58 24.94634131100611 0.01580774951793931 0.01288082480430603
59 24.91787903700606 0.016089849033138967 0.016915994882583617
60 24.971078126021894 0.017410860937201615 0.010604381561279297
61 24.911027816997375 0.014818417620929804 0.012530055046081543
62 24.840705070993863 0.018199128990372022 0.012416390776634216
63 24.986436909006443 0.014183150794921499 0.013823288083076478
64 24.736250593006844 0.014346325878844117 0.010188156068325042
65 24.890634923009202 0.014000997120683844 0.009128284454345704
66 24.9069201000093 0.013639519919951756 0.009772914946079254
67 24.51474503200734 0.013269842787222428 0.011838412582874299
68 24.912556983006652 0.013160945784865003 0.009126562178134918
69 24.82944539899472 0.012550250436772 0.009450287222862244
70 24.66010346301482 0.01251265822576754 0.010281450748443603
71 24.888258936000057 0.012075872359853803 0.007939353287220001
72 24.59701405800297 0.011801689530863906 0.010234140753746034
73 24.902602474991 0.011442675096067514 0.008392866253852844
74 24.917132714996114 0.011121287219452136 0.009120062589645386
75 24.83201777600334 0.011003146488106613 0.007253599166870117
76 24.89453538300586 0.010614384728850741 0.007755649387836456
77 24.23423577498761 0.010268583719477508 0.007972545325756072
78 24.909075931995176 0.010110552486596685 0.007547782361507415
79 24.896849734010175 0.009826866959080551 0.007634985148906708
80 24.900936455000192 0.009628959915854714 0.006657314002513886
81 24.862265364004998 0.009304989472031594 0.006887767910957337
82 24.85231573402416 0.009144188334544499 0.005851777493953705
83 24.872531698987586 0.008852494974931081 0.006661068797111511
84 24.917733587994007 0.008661264250224288 0.006412217617034912
85 24.950434097001562 0.008448194947206613 0.0060738718509674074
86 24.923266985017108 0.008245871221025785 0.005760520100593567
87 24.857623737014364 0.008056700465354052 0.005715223103761673
88 24.907449998980155 0.007893827532276963 0.005730432271957397
89 24.859562830999494 0.007735359451535976 0.0055146531760692594
90 24.928412691981066 0.007586226686609514 0.005309851765632629
91 23.90444998300518 0.007477327289454864 0.005635140389204025
92 24.784806112991646 0.007360481213891145 0.005256103277206421
93 24.948482228996 0.007256498729415012 0.005119110643863678
94 24.862261277012294 0.007165880830450492 0.005083552151918411
95 24.874776940996526 0.007088532322058172 0.005167713761329651
96 24.59594982699491 0.007029113668835524 0.005046055614948273
97 24.86109956697328 0.0069825279376271995 0.005091867744922638
98 24.916252797003835 0.006954560896212404 0.005013482421636581
99 24.87029805200291 0.006941256832670082 0.005011018812656403
Time taken for predictions on new_test.mat: 0.08225772398873232 seconds
Job finished with exit code 0 at: Sun 24 Nov 2024 07:08:15 PM EST
