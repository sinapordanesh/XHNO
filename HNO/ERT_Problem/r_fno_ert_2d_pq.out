Starting run at: Wed 20 Nov 2024 05:37:11 PM EST
/home/sinpo/repos/XNO/HNO/ERT_Problem/./ERT_fourier.py:474: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load('best_modelPQ1_F.pth'))
torch.Size([66000, 40, 100])
torch.Size([66000, 40, 100])
torch.Size([100, 40, 100])
torch.Size([100, 40, 100])
torch.Size([100, 40, 100])
torch.Size([100, 40, 100])
40
100
999937
0 17.48954448697623 0.13363906158461716 0.08260868549346924
1 16.17339037405327 0.06195627915317362 0.06307159900665284
2 16.434720692923293 0.052108128627141315 0.020150530338287353
3 16.278602163074538 0.05200811691988598 0.018439515829086303
4 16.11158606794197 0.04127043756481373 0.023942265510559082
5 16.05950977501925 0.04510060401486628 0.015452075004577636
6 15.976888451958075 0.034311063459425264 0.015234428644180297
7 16.080398077028804 0.03534620903658144 0.03299240231513977
8 16.565184617997147 0.03638424170107552 0.019277409315109253
9 16.29087057802826 0.038411223008777154 0.01510872781276703
10 16.132962458999828 0.03368036900054325 0.015526921153068543
11 16.194795618997887 0.03271629513122819 0.012930753231048584
12 16.393961193040013 0.031623188854166956 0.018794367909431457
13 16.118800608906895 0.028955962202765726 0.015885879993438722
14 16.16625276801642 0.034304652642120015 0.014913605451583862
15 15.962498012930155 0.025975248385559428 0.017154480814933776
16 16.249453169992194 0.029850291107640124 0.015284320712089539
17 16.0591478649294 0.028208414843588166 0.010912567377090454
18 16.808314627036452 0.02915207814809048 0.012680396437644958
19 16.06829123699572 0.03126440967754884 0.01787699818611145
20 16.051024217973463 0.02711751818295681 0.05282832622528076
21 16.113793469965458 0.02740280666134574 0.015477501153945923
22 16.0187459589215 0.027479437045075678 0.021166282296180724
23 16.19784527400043 0.02404015539812319 0.016068859696388244
24 16.152651279000565 0.024658458604957117 0.01482417106628418
25 16.148914543911815 0.022868627001841862 0.017301236987113954
26 16.156566879944876 0.026110414199756852 0.014642972946166993
27 16.21384817000944 0.019449466995217584 0.04875144720077515
28 16.108566781971604 0.022890171034769577 0.015646833777427673
29 16.021481608971953 0.022012834190419227 0.013890174627304077
30 16.069417265010998 0.02049111281561129 0.01591001808643341
31 16.367775799008086 0.024230394931453646 0.016168400049209594
32 16.06795446202159 0.023814218147234483 0.014275930523872375
33 16.153056801995263 0.017115273161819485 0.009760467410087586
34 16.06159820605535 0.023640784736835594 0.00994502305984497
35 16.031810011016205 0.02024166170665712 0.013774312734603882
36 16.23718669207301 0.01917199636453932 0.014308934807777405
37 16.0929371699458 0.01976956912062385 0.01449604332447052
38 16.255639999057166 0.01958331602450573 0.009613081812858582
39 16.723071133950725 0.02029706519887303 0.019322389364242555
40 16.28305560804438 0.015726367085269 0.010698384046554566
41 16.23601769201923 0.021189959406852723 0.008535324037075043
42 16.176475606975146 0.015322869077324868 0.014098737835884095
43 16.072489618090913 0.019507500168952075 0.009684436023235321
44 16.136636952054687 0.01813092845001004 0.011335625648498535
45 16.034660798031837 0.019386330001281968 0.015273479223251342
46 16.154934866935946 0.014600791373939225 0.009984119534492493
47 16.095249162055552 0.018127073711066536 0.01702439069747925
48 16.272628228995018 0.014443974762251883 0.023441497683525086
49 16.51137441606261 0.015008165176619183 0.014344943761825562
50 16.26008570799604 0.018960812405654878 0.012623401284217834
51 16.291289416956715 0.01420200838329214 0.008779516220092773
52 16.210029308917 0.016143253714297756 0.009319255352020264
53 16.02697480202187 0.013826769188498006 0.010553781986236572
54 15.939955945010297 0.016963355973362924 0.009225132167339325
55 16.41964924300555 0.01430178288076863 0.008061805963516236
56 16.759879013057798 0.016325048700426566 0.0655101466178894
57 16.24078842101153 0.013961411825183666 0.01041959524154663
58 16.245127698988654 0.01291818481548266 0.0098118257522583
59 16.1071267320076 0.015348422629363609 0.009626001715660096
60 15.91670470603276 0.01238954690776088 0.007850365042686462
61 16.389022731920704 0.013386247207721075 0.009317004680633545
62 16.626583723002113 0.012252614329258601 0.008702644109725953
63 16.207402294036 0.013436461775140329 0.013696032166481019
64 16.21799979300704 0.011950316793087758 0.007851797044277192
65 16.127640017075464 0.011872999846483722 0.007846300601959228
66 16.585758403060026 0.011526723695072261 0.008867175281047822
67 16.291762685985304 0.01155291263443051 0.007698373794555664
68 16.075295501970686 0.011723546743392944 0.008573788702487945
69 16.77075706992764 0.011343803831573688 0.006393055915832519
70 16.846838957979344 0.010605236021406722 0.0078034475445747375
71 16.37458278890699 0.010584015639893937 0.006590315699577331
72 16.48043183295522 0.010681872511903445 0.009468854069709778
73 16.315383740933612 0.010182033443089688 0.006338828206062317
74 16.921459637000225 0.012007170521851742 0.00690070390701294
75 17.03052315104287 0.009609249170530926 0.006640453338623047
76 16.784330490976572 0.009317707018418745 0.006416928172111511
77 16.754919326049276 0.00956874333051118 0.005839293599128723
78 16.748235304025002 0.009239668956760204 0.006908406019210816
79 17.10643947904464 0.009201438981926803 0.005843068957328796
80 17.11280340794474 0.009090609967708588 0.00572820395231247
81 17.068834458943456 0.008862876123551166 0.004886951297521591
82 17.24828704702668 0.008532468619220185 0.006346414387226104
83 16.78823697590269 0.008343074715498722 0.004761704057455063
84 17.03194095706567 0.008168721464998795 0.005306913703680039
85 16.865051625063643 0.008108358205945203 0.0053184604644775394
86 16.122885129996575 0.007814040240464788 0.0046567201614379885
87 16.083173551014625 0.00781461636383425 0.0051282145082950596
88 16.16049846203532 0.007556448724459518 0.004798599630594254
89 16.03982496401295 0.0073240763276363864 0.005399648249149323
90 15.9505012370646 0.007233485395483899 0.004476324170827866
91 15.941498580970801 0.007144008044266339 0.00439867377281189
92 16.129850602010265 0.006952829409277801 0.0045107202231884
93 16.401419445988722 0.006694759104965311 0.003885311335325241
94 16.10930847504642 0.006609462232074955 0.005456940680742264
95 16.178029811009765 0.006433367575885671 0.004206514954566956
96 16.162471494986676 0.006237007267321601 0.003844255805015564
97 16.009969505947083 0.006184505052864551 0.0031440488249063494
98 16.07823822007049 0.006001542474058541 0.003926600515842438
99 16.033907033968717 0.0058527517571593775 0.0035378439724445343
Time taken for predictions on new_test.mat: 0.023799007991328835 seconds
Job finished with exit code 0 at: Wed 20 Nov 2024 06:04:52 PM EST
