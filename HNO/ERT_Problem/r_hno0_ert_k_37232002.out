Starting run at: Sun 24 Nov 2024 07:25:32 PM EST
/home/sinpo/repos/XNO/HNO/ERT_Problem/ERT_hilbert.py:501: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(f"best_model_{pfn}.pth"))
torch.Size([80000, 40, 100])
torch.Size([80000, 40, 100])
torch.Size([100, 40, 100])
torch.Size([100, 40, 100])
torch.Size([100, 40, 100])
torch.Size([100, 40, 100])
40
100
Devide is: cuda
999937
0 33.071995033998974 0.2411774163901806 0.17271777153015136
1 31.659577275997435 0.14168709653913975 0.23770461082458497
2 31.812772241006314 0.12272638909220696 0.17815738677978515
3 31.737545146002958 0.11068437738120555 0.14570750236511232
4 31.85603267999977 0.10956464528739453 0.07806172609329223
5 31.832431741997425 0.10380507953763009 0.09072412490844727
6 31.831430340003863 0.09848323260843754 0.08253637313842774
7 31.784213334001834 0.0946512186318636 0.06773380994796753
8 31.78370530900429 0.0921131067365408 0.11026345729827881
9 31.728430002003734 0.0912747626364231 0.08327899932861328
10 31.843918994003616 0.09324325744509697 0.0977257251739502
11 32.09525484099868 0.08307193173766136 0.08498497009277343
12 31.97070073299983 0.09150266149938106 0.08209691524505615
13 31.83039899099822 0.08417351963222026 0.08787635564804078
14 31.776367375998234 0.0864938431352377 0.07443691968917847
15 31.840122359004454 0.07989306183159352 0.1665705394744873
16 31.842251668000245 0.0778852861225605 0.0580603551864624
17 31.85635209299653 0.0903011473685503 0.08464069366455078
18 31.877952244998596 0.07736536891460419 0.07645515203475953
19 31.82022328399762 0.07709327238202095 0.06297183036804199
20 31.87798802799807 0.07545592567324638 0.06925684452056885
21 31.856089347995294 0.07330464183390141 0.0790246844291687
22 31.895086971999262 0.07150656470656395 0.05368276834487915
23 31.770829600995057 0.07421657292246818 0.06524853944778443
24 31.870409955001378 0.06845607573091984 0.05139595031738281
25 31.802300919000118 0.08046778407990933 0.068726806640625
26 31.760680931001843 0.07079472511410713 0.11237766742706298
27 31.730509786997573 0.06875271772146226 0.13044950008392334
28 31.827054260000295 0.07292246369123459 0.07309395790100098
29 31.728917241998715 0.06550323708355427 0.05690218925476074
30 31.83821524099767 0.06774445496797561 0.06508930683135987
31 31.77677641400078 0.06479255085140467 0.07552308082580567
32 31.81194470199989 0.0645426394149661 0.10095497131347657
33 31.800832902001275 0.06511994888484478 0.12666374206542969
34 31.81373841599998 0.06403292448222637 0.054381654262542725
35 31.809904055000516 0.06489651803821325 0.05881891489028931
36 31.858541285000683 0.0611648187443614 0.09368511199951172
37 31.850394881003012 0.06013224997371435 0.04747232437133789
38 31.835829613999522 0.06300720003694296 0.05795389890670776
39 31.87144122600148 0.055307381670176986 0.04899689912796021
40 31.873785126001167 0.05961314190030098 0.05373896598815918
41 31.88212939499499 0.05685733259022236 0.04507700204849243
42 31.859195049000846 0.05323653851002455 0.05440077066421509
43 31.85266310300358 0.053136730143427846 0.047213358879089354
44 31.81983408400265 0.05860372836440802 0.05161690950393677
45 32.14596264300053 0.05341862709969282 0.04394472599029541
46 31.91279374199803 0.05078276968300342 0.07078338623046875
47 31.924693588000082 0.05173786567151546 0.08610581874847412
48 31.937402083996858 0.050390905198454856 0.05407420158386231
49 31.920888038002886 0.048178425914049146 0.04865243911743164
50 31.866041717999906 0.04902043114155531 0.05006103754043579
51 31.814369453000836 0.04698254174143076 0.044208543300628664
52 31.876967536998563 0.04347308334857226 0.050005984306335446
53 31.764148786001897 0.04394549773931503 0.04389421939849854
54 31.78439783200156 0.045767589162290095 0.04526318550109863
55 31.77872086899879 0.042405644354224205 0.04391657829284668
56 31.821633807005128 0.042687247286736965 0.0495614504814148
57 31.778586051004822 0.04333485494405031 0.042486448287963864
58 31.69471368599625 0.040609955735504626 0.04914243459701538
59 31.893501767997805 0.03906481759995222 0.040474092960357665
60 31.898224644006405 0.039100271387398244 0.03946150779724121
61 31.838395299004333 0.03353416783511639 0.03873350381851196
62 31.918835941003636 0.03699223974347115 0.03583529829978943
63 31.873134243003733 0.03589636097550392 0.038499550819396974
64 31.812629216998175 0.03565511375069618 0.039774430990219115
65 31.929941444999713 0.0315829371124506 0.038037211894989015
66 31.87522778600396 0.03240832760930061 0.03910217523574829
67 31.90798300199822 0.030680635526776315 0.033972731828689574
68 31.860452537002857 0.03125550706088543 0.03091267704963684
69 31.88122768800531 0.030495667439699174 0.03362202763557434
70 31.721667493002315 0.028643625225126743 0.03133833408355713
71 31.86513220800407 0.028348550844192504 0.030169334411621094
72 31.883539766000467 0.02778720631301403 0.030326428413391112
73 31.9056208539987 0.027364779625833033 0.026980687379837037
74 31.925371396995615 0.026521245862543584 0.02698513984680176
75 31.798599011002807 0.02613640359044075 0.028972952365875243
76 31.846402116003446 0.025260340782999994 0.026865813732147217
77 31.873484278999968 0.024675515719503164 0.02606075406074524
78 31.906211482004437 0.024128738782554865 0.028231227397918703
79 31.928708332001406 0.023522609370201827 0.025283968448638915
80 31.803675609000493 0.022858386271446943 0.02579807996749878
81 31.90654584099684 0.022463371843844653 0.022801612615585328
82 31.832748866996553 0.021740594286471605 0.023574494123458863
83 31.813339717999042 0.02129679996371269 0.0225364089012146
84 31.88415892500052 0.02082219697088003 0.022396944761276245
85 31.853013940999517 0.020238115137815475 0.022742305994033814
86 31.873509272001684 0.019896164658665658 0.02288865566253662
87 31.872394717000134 0.01930596007183194 0.02207869291305542
88 31.86840190499788 0.018911026726663113 0.021376444697380065
89 31.92968056799873 0.01850138768479228 0.020837457776069643
90 31.901274520998413 0.018092432211339472 0.0209429532289505
91 32.25820290399861 0.017807181852310897 0.02010290265083313
92 31.819051463004143 0.01754020447060466 0.019582910537719725
93 31.797475103005127 0.017232900577038527 0.020007672309875487
94 31.74443828400399 0.017000309083610773 0.019671084880828856
95 31.808411575999344 0.016827380964905023 0.019356170892715453
96 31.84412142999645 0.016687858179956674 0.019167865514755248
97 31.884808096998313 0.0165881654240191 0.019101294875144958
98 31.867882426995493 0.01651966760903597 0.019073101878166198
99 31.864123959006974 0.016483099384605883 0.019098042249679564
Time taken for predictions on new_test.mat: 0.02752520599460695 seconds
Job finished with exit code 0 at: Sun 24 Nov 2024 08:19:25 PM EST
