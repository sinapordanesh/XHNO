Starting run at: Sat 02 Nov 2024 04:56:18 PM EDT
/home/sinpo/repos/XNO/ERT_Problem/./ERT_fourier.py:477: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load('best_modelV1.pth'))
torch.Size([80000, 40, 100])
torch.Size([80000, 40, 100])
torch.Size([100, 40, 100])
torch.Size([100, 40, 100])
torch.Size([100, 40, 100])
torch.Size([100, 40, 100])
40
100
999937
0 28.542048813891597 0.15876493828594684 0.11933727264404297
1 25.48643989500124 0.08322045949101448 0.054710118770599364
2 29.690173811046407 0.06746286840289831 0.05683539152145386
3 28.841208986006677 0.062680661252141 0.05958091735839844
4 27.650271295104176 0.05940469849407673 0.03690449953079224
5 26.432135282084346 0.060797846502065656 0.03984024167060852
6 26.654711502953433 0.05185520449429751 0.14149755001068115
7 26.152243623975664 0.04689835097491741 0.03282982110977173
8 25.86489597905893 0.050830088652670385 0.04167634010314941
9 25.174807842005976 0.04247358661442995 0.044960930347442626
10 24.829156554071233 0.051162112495303155 0.03964961886405945
11 26.250305711990222 0.044498469312489033 0.0349171781539917
12 28.33833534596488 0.044276719729602336 0.10370234489440917
13 24.881063951994292 0.03981952615529299 0.04054776430130005
14 25.522501054103486 0.04278269754499197 0.03232532024383545
15 25.927430517040193 0.03873932536244393 0.03877511739730835
16 27.11074065801222 0.039025548139214515 0.03268405914306641
17 26.158894957974553 0.04678179848790169 0.031675574779510496
18 25.963006751029752 0.03322849510014057 0.03175536036491394
19 25.938788415980525 0.03678026614189148 0.034367811679840085
20 24.696430142968893 0.039166232170164586 0.03301008701324463
21 26.63642727106344 0.03984025290459395 0.03843985795974732
22 26.19466223695781 0.035081313183903694 0.029751830101013184
23 25.268880461109802 0.03423656615167856 0.03283075094223022
24 25.380435480969027 0.033270310473442075 0.029784137010574342
25 25.18866112397518 0.03496642362177372 0.03657840013504028
26 27.302173719974235 0.031905993407964704 0.031813682317733766
27 25.449565234943293 0.03590333830192685 0.050564661026000976
28 26.191046959953383 0.028329216669499873 0.029768773317337037
29 25.612684862921014 0.03237204080373049 0.031429381370544435
30 26.21645599498879 0.03038056886792183 0.032014342546463015
31 27.574115872965194 0.03363595634996891 0.03155983209609985
32 26.08916125399992 0.031591955532878635 0.036923732757568356
33 25.291963926050812 0.027339544931799173 0.0258324658870697
34 25.762024287017994 0.03027465477362275 0.025116206407546998
35 25.74111156805884 0.03044437520802021 0.036479071378707886
36 27.121518883039244 0.02700816009491682 0.03542454481124878
37 25.531278218026273 0.02688941472992301 0.0390033233165741
38 25.367912590969354 0.028889804702997207 0.02591609001159668
39 26.280506737995893 0.028896282889693977 0.02508854866027832
40 25.5113600960467 0.024944001916050913 0.025404454469680787
41 27.108783086994663 0.027827906335145234 0.023795679807662964
42 25.890882913954556 0.023687983577698468 0.02908737540245056
43 26.333997957990505 0.02422350532785058 0.02549916982650757
44 25.77570504299365 0.02775686333477497 0.02726864457130432
45 25.75146355794277 0.02310286885127425 0.023928462266921996
46 27.037733010947704 0.023771725629270078 0.03571606755256653
47 25.775969365029596 0.022991170191019775 0.022217854261398315
48 25.74674070207402 0.024268645434826614 0.027284343242645264
49 25.759385962970555 0.022130909448117016 0.02449690580368042
50 25.759858976933174 0.02228811517953873 0.01886010468006134
51 27.715291253989562 0.021482333879172803 0.023405849933624268
52 26.52015009894967 0.021356092423945667 0.01888008713722229
53 26.184855429106392 0.021192680270969867 0.020879743099212648
54 26.88050197099801 0.020430325805395843 0.023855637311935424
55 26.108964135986753 0.019995285750925542 0.018133325576782225
56 26.69065306999255 0.019652427411079407 0.025909298658370973
57 26.203015399049036 0.019293319711089135 0.023032511472702025
58 26.26664653699845 0.018865094352513552 0.019707468152046204
59 24.943274626974016 0.01864862105026841 0.01892276406288147
60 26.87728340004105 0.018248179465532303 0.02034658968448639
61 27.648577561951242 0.017898858573287726 0.016947189569473265
62 27.91864007897675 0.017587266592681408 0.020702956914901732
63 28.049359105993062 0.017048529383540154 0.02020140886306763
64 28.57290848402772 0.016760020662844183 0.016917808651924132
65 28.848601077101193 0.016579886686056852 0.01884666323661804
66 26.368161340942606 0.016077777560800314 0.017381527423858643
67 25.755817987956107 0.015654066628217698 0.016248742341995238
68 25.248439598013647 0.01555869275033474 0.015960506796836853
69 25.188113196054474 0.014937905719131232 0.015583580136299133
70 26.023983358056284 0.014827315360307694 0.01573416233062744
71 25.89085744600743 0.014481064300239085 0.014395058751106263
72 26.755279434961267 0.014123063698410989 0.013766456842422486
73 26.028223931090906 0.01388423877581954 0.013475881814956665
74 27.192155252909288 0.01357411523386836 0.014082294702529908
75 27.107747967005707 0.013283278796449303 0.013392704725265502
76 25.97735559695866 0.012907013447582721 0.013687390685081482
77 25.432349935057573 0.012660512278974056 0.012354617714881897
78 27.24709008797072 0.012504911647364498 0.01282793164253235
79 26.18976078601554 0.012078020354360341 0.012137995362281799
80 26.020657408982515 0.011869021457061172 0.012887415289878846
81 25.040532538085245 0.01158177236430347 0.012128254175186157
82 25.893240328063257 0.011341669547185301 0.011718138456344604
83 25.337847427930683 0.011073960345610976 0.012187063097953796
84 27.62046239199117 0.010888271893560886 0.01108924150466919
85 25.599053613026626 0.010616709269210696 0.011474121809005738
86 25.643166351947002 0.010378914006054401 0.010789342522621155
87 27.15389147901442 0.010205810382589699 0.010873982310295105
88 26.56909252598416 0.009992185010388493 0.010794195532798766
89 27.979409593041055 0.009795223175361753 0.01006918489933014
90 26.58840502006933 0.009622679423540831 0.010666936933994293
91 25.830453965929337 0.009493116600066423 0.010314841568470002
92 25.289511317037977 0.00932451863475144 0.009874974489212035
93 25.78433839196805 0.009199661268293857 0.00955130636692047
94 28.180481395102106 0.009100109286233784 0.009553537964820861
95 26.06410554202739 0.009003002285212279 0.00947534441947937
96 25.263898479985073 0.008923546608537435 0.00960870236158371
97 26.658052888000384 0.008869795397669076 0.009408328831195831
98 27.522193528013304 0.008834103945270181 0.009425130784511565
99 25.88566358096432 0.008814309554174542 0.009425576329231262
Time taken for predictions on new_test.mat: 0.016612329985946417 seconds
Job finished with exit code 0 at: Sat 02 Nov 2024 05:40:57 PM EDT
